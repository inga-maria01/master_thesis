{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_idx_df = pd.read_excel('https://raw.githubusercontent.com/inga-maria01/master_thesis/main/index/sentiment_index_unweighted_v7.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>17.132027</td>\n",
       "      <td>-1.195109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>14.827878</td>\n",
       "      <td>-0.130807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>18.088204</td>\n",
       "      <td>0.938619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>16.568480</td>\n",
       "      <td>1.079692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>18.532825</td>\n",
       "      <td>-1.688521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>22.540491</td>\n",
       "      <td>2.444858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>25.024275</td>\n",
       "      <td>-1.818651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>26.507670</td>\n",
       "      <td>-0.658612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>23.692474</td>\n",
       "      <td>-0.751765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>24.445917</td>\n",
       "      <td>-1.177096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  sentiment_score  sentiment_slope\n",
       "0    2015-01-01        17.132027        -1.195109\n",
       "1    2015-01-02        14.827878        -0.130807\n",
       "2    2015-01-03        18.088204         0.938619\n",
       "3    2015-01-04        16.568480         1.079692\n",
       "4    2015-01-05        18.532825        -1.688521\n",
       "...         ...              ...              ...\n",
       "1821 2019-12-27        22.540491         2.444858\n",
       "1822 2019-12-28        25.024275        -1.818651\n",
       "1823 2019-12-29        26.507670        -0.658612\n",
       "1824 2019-12-30        23.692474        -0.751765\n",
       "1825 2019-12-31        24.445917        -1.177096\n",
       "\n",
       "[1826 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_idx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               datetime64[ns]\n",
       "sentiment_score           float64\n",
       "sentiment_slope           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_idx_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing days\n",
    "import pandas as pd\n",
    "\n",
    "def find_missing_days(df, date_col='date', start_date='2015-01-01', end_date='2019-12-31'):\n",
    "    \"\"\"\n",
    "    Find missing dates within a specified range in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a date column.\n",
    "        date_col (str): The name of the date column in the DataFrame.\n",
    "        start_date (str): The start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): The end date in 'YYYY-MM-DD' format.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DatetimeIndex: An index of missing dates.\n",
    "    \"\"\"\n",
    "    # Ensure the date column is a datetime type\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # Filter the data to the specified range\n",
    "    df = df[(df[date_col] >= start_date) & (df[date_col] <= end_date)]\n",
    "    \n",
    "    # Set the date column as index if not already set\n",
    "    df.set_index(date_col, inplace=True)\n",
    "    \n",
    "    # Generate a complete date range with daily frequency\n",
    "    full_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    # Identify missing dates by finding the difference\n",
    "    missing_dates = full_range.difference(df.index)\n",
    "    \n",
    "    return missing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex([], dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "missing_days = find_missing_days(sentiment_idx_df, date_col='date', start_date='2015-01-01', end_date='2019-12-31')\n",
    "print(missing_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing dates!\n",
    "\n",
    "Next, do the Markov-switching regression (MRS) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "\n",
    "df = sentiment_idx_df.copy()\n",
    "# set date as index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Instantiate a two-state Markov-Switching Regression model\n",
    "model = MarkovRegression(df['sentiment_score'], k_regimes=2, trend='c', switching_variance=True)\n",
    "\n",
    "# Fit the model to the data\n",
    "result = model.fit()\n",
    "\n",
    "# Predict the next regime based on the current states\n",
    "predicted_regimes = result.predict(n_periods=1)\n",
    "\n",
    "# Access the predicted regime for the next day\n",
    "next_day_regime = predicted_regimes[-1]\n",
    "\n",
    "# Get full summary of results\n",
    "summary = result.summary()\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sentiment_idx_df.copy()\n",
    "\n",
    "# set date as index\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_slope</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>17.132027</td>\n",
       "      <td>-1.195109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>14.827878</td>\n",
       "      <td>-0.130807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>18.088204</td>\n",
       "      <td>0.938619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-04</th>\n",
       "      <td>16.568480</td>\n",
       "      <td>1.079692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>18.532825</td>\n",
       "      <td>-1.688521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>22.540491</td>\n",
       "      <td>2.444858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>25.024275</td>\n",
       "      <td>-1.818651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>26.507670</td>\n",
       "      <td>-0.658612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>23.692474</td>\n",
       "      <td>-0.751765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>24.445917</td>\n",
       "      <td>-1.177096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment_score  sentiment_slope\n",
       "date                                        \n",
       "2015-01-01        17.132027        -1.195109\n",
       "2015-01-02        14.827878        -0.130807\n",
       "2015-01-03        18.088204         0.938619\n",
       "2015-01-04        16.568480         1.079692\n",
       "2015-01-05        18.532825        -1.688521\n",
       "...                     ...              ...\n",
       "2019-12-27        22.540491         2.444858\n",
       "2019-12-28        25.024275        -1.818651\n",
       "2019-12-29        26.507670        -0.658612\n",
       "2019-12-30        23.692474        -0.751765\n",
       "2019-12-31        24.445917        -1.177096\n",
       "\n",
       "[1826 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/friederikeeichholz/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/friederikeeichholz/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/regime_switching/markov_switching.py:1502: RuntimeWarning: divide by zero encountered in divide\n",
      "  unconstrained[s] = -np.log(1. / constrained[s] - 1)\n",
      "/Users/friederikeeichholz/anaconda3/lib/python3.11/site-packages/statsmodels/tools/numdiff.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  increments = np.identity(n) * 1j * epsilon\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Steady-state probabilities could not be constructed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/regime_switching/markov_switching.py:588\u001b[0m, in \u001b[0;36mMarkovSwitching.initial_probabilities\u001b[0;34m(self, params, regime_transition)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(A)[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/linalg/linalg.py:1983\u001b[0m, in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   1982\u001b[0m a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mconjugate()\n\u001b[0;32m-> 1983\u001b[0m u, s, vt \u001b[38;5;241m=\u001b[39m svd(a, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, hermitian\u001b[38;5;241m=\u001b[39mhermitian)\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;66;03m# discard small singular values\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/linalg/linalg.py:1642\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1641\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1642\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m gufunc(a, signature\u001b[38;5;241m=\u001b[39msignature, extobj\u001b[38;5;241m=\u001b[39mextobj)\n\u001b[1;32m   1643\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/linalg/linalg.py:98\u001b[0m, in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_svd_nonconvergence\u001b[39m(err, flag):\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_data\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#print(len(train_data))\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     model \u001b[38;5;241m=\u001b[39m MarkovRegression(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m], k_regimes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, trend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m, switching_variance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 21\u001b[0m     model_fit \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m#forecast = model_fit.predict(start=len(train_data), end=len(train_data))\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# forecast = model_fit.forecast(steps=1)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# get_forecast = model_fit.get_forecast(steps=1)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# prediction = model_fit.predict(start=df.index[-1], end=df.index[-1] + pd.Timedelta(days=1))\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mpredict(start\u001b[38;5;241m=\u001b[39mtest_data\u001b[38;5;241m.\u001b[39mindex[i], end\u001b[38;5;241m=\u001b[39mtest_data\u001b[38;5;241m.\u001b[39mindex[i])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/regime_switching/markov_switching.py:1124\u001b[0m, in \u001b[0;36mMarkovSwitching.fit\u001b[0;34m(self, start_params, transformed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, em_iter, search_reps, search_iter, search_scale, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# Maximum likelihood estimation by scoring\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m fargs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mFalse\u001b[39;00m,)\n\u001b[0;32m-> 1124\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(MarkovSwitching, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(start_params, method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   1125\u001b[0m                                           fargs\u001b[38;5;241m=\u001b[39mfargs,\n\u001b[1;32m   1126\u001b[0m                                           maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[1;32m   1127\u001b[0m                                           full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[1;32m   1128\u001b[0m                                           disp\u001b[38;5;241m=\u001b[39mdisp, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m   1129\u001b[0m                                           skip_hessian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:566\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_t\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    565\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[0;32m--> 566\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39m_fit(f, score, start_params,\n\u001b[1;32m    567\u001b[0m                                                fargs, kwargs,\n\u001b[1;32m    568\u001b[0m                                                hessian\u001b[38;5;241m=\u001b[39mhess,\n\u001b[1;32m    569\u001b[0m                                                method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    570\u001b[0m                                                disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[1;32m    571\u001b[0m                                                maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[1;32m    572\u001b[0m                                                callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    573\u001b[0m                                                retall\u001b[38;5;241m=\u001b[39mretall,\n\u001b[1;32m    574\u001b[0m                                                full_output\u001b[38;5;241m=\u001b[39mfull_output)\n\u001b[1;32m    575\u001b[0m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[1;32m    576\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/optimizer.py:242\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    239\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[1;32m    241\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[0;32m--> 242\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m func(objective, gradient, start_params, fargs, kwargs,\n\u001b[1;32m    243\u001b[0m                      disp\u001b[38;5;241m=\u001b[39mdisp, maxiter\u001b[38;5;241m=\u001b[39mmaxiter, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    244\u001b[0m                      retall\u001b[38;5;241m=\u001b[39mretall, full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[1;32m    245\u001b[0m                      hess\u001b[38;5;241m=\u001b[39mhessian)\n\u001b[1;32m    247\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[1;32m    248\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[1;32m    249\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    250\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_fit_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_fit_funcs}\n\u001b[1;32m    251\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/optimizer.py:537\u001b[0m, in \u001b[0;36m_fit_bfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    535\u001b[0m norm \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mInf)\n\u001b[1;32m    536\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1.4901161193847656e-08\u001b[39m)\n\u001b[0;32m--> 537\u001b[0m retvals \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mfmin_bfgs(f, start_params, score, args\u001b[38;5;241m=\u001b[39mfargs,\n\u001b[1;32m    538\u001b[0m                              gtol\u001b[38;5;241m=\u001b[39mgtol, norm\u001b[38;5;241m=\u001b[39mnorm, epsilon\u001b[38;5;241m=\u001b[39mepsilon,\n\u001b[1;32m    539\u001b[0m                              maxiter\u001b[38;5;241m=\u001b[39mmaxiter, full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[1;32m    540\u001b[0m                              disp\u001b[38;5;241m=\u001b[39mdisp, retall\u001b[38;5;241m=\u001b[39mretall, callback\u001b[38;5;241m=\u001b[39mcallback)\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m retall:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:1359\u001b[0m, in \u001b[0;36mfmin_bfgs\u001b[0;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback, xrtol)\u001b[0m\n\u001b[1;32m   1351\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgtol\u001b[39m\u001b[38;5;124m'\u001b[39m: gtol,\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m: norm,\n\u001b[1;32m   1353\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m: epsilon,\n\u001b[1;32m   1354\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp,\n\u001b[1;32m   1355\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter,\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_all\u001b[39m\u001b[38;5;124m'\u001b[39m: retall}\n\u001b[1;32m   1358\u001b[0m callback \u001b[38;5;241m=\u001b[39m _wrap_callback(callback)\n\u001b[0;32m-> 1359\u001b[0m res \u001b[38;5;241m=\u001b[39m _minimize_bfgs(f, x0, args, fprime, callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[1;32m   1362\u001b[0m     retlist \u001b[38;5;241m=\u001b[39m (res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhess_inv\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   1363\u001b[0m                res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnjev\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:1418\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, xrtol, **unknown_options)\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxiter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1416\u001b[0m     maxiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x0) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m-> 1418\u001b[0m sf \u001b[38;5;241m=\u001b[39m _prepare_scalar_function(fun, x0, jac, args\u001b[38;5;241m=\u001b[39margs, epsilon\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   1419\u001b[0m                               finite_diff_rel_step\u001b[38;5;241m=\u001b[39mfinite_diff_rel_step)\n\u001b[1;32m   1421\u001b[0m f \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m   1422\u001b[0m myfprime \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:383\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    379\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m sf \u001b[38;5;241m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m    384\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[38;5;241m=\u001b[39mepsilon)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:177\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m approx_derivative(fun_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, f0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf,\n\u001b[1;32m    174\u001b[0m                                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfinite_diff_options)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad_impl \u001b[38;5;241m=\u001b[39m update_grad\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Hessian Evaluation\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(hess):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad_impl()\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:167\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_grad\u001b[39m():\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m grad_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:164\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.grad_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_wrapped\u001b[39m(x):\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(grad(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:545\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.score\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(params, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m/\u001b[39m nobs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/regime_switching/markov_switching.py:991\u001b[0m, in \u001b[0;36mMarkovSwitching.score\u001b[0;34m(self, params, transformed)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;124;03mCompute the score function at params.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;124;03m    Whether or not `params` is already transformed. Default is True.\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    989\u001b[0m params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(params, ndmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 991\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m approx_fprime_cs(params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglike, args\u001b[38;5;241m=\u001b[39m(transformed,))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tools/numdiff.py:251\u001b[0m, in \u001b[0;36mapprox_fprime_cs\u001b[0;34m(x, f, epsilon, args, kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m increments \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(n) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m epsilon\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# TODO: see if this can be vectorized, but usually dim is small\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m partials \u001b[38;5;241m=\u001b[39m [f(x\u001b[38;5;241m+\u001b[39mih, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mimag \u001b[38;5;241m/\u001b[39m epsilon[i]\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i, ih \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(increments)]\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(partials)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tools/numdiff.py:251\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    249\u001b[0m increments \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(n) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m epsilon\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# TODO: see if this can be vectorized, but usually dim is small\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m partials \u001b[38;5;241m=\u001b[39m [f(x\u001b[38;5;241m+\u001b[39mih, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mimag \u001b[38;5;241m/\u001b[39m epsilon[i]\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i, ih \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(increments)]\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(partials)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/regime_switching/markov_switching.py:975\u001b[0m, in \u001b[0;36mMarkovSwitching.loglike\u001b[0;34m(self, params, transformed)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloglike\u001b[39m(\u001b[38;5;28mself\u001b[39m, params, transformed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    964\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;124;03m    Loglikelihood evaluation\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03m        Whether or not `params` is already transformed. Default is True.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglikeobs(params, transformed))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/regime_switching/markov_switching.py:959\u001b[0m, in \u001b[0;36mMarkovSwitching.loglikeobs\u001b[0;34m(self, params, transformed)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transformed:\n\u001b[1;32m    957\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_params(params)\n\u001b[0;32m--> 959\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter(params)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;241m5\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/regime_switching/markov_switching.py:771\u001b[0m, in \u001b[0;36mMarkovSwitching._filter\u001b[0;34m(self, params, regime_transition)\u001b[0m\n\u001b[1;32m    769\u001b[0m     regime_transition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregime_transition_matrix(params)\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# Get the initial probabilities\u001b[39;00m\n\u001b[0;32m--> 771\u001b[0m initial_probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_probabilities(\n\u001b[1;32m    772\u001b[0m     params, regime_transition)\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# Compute the conditional likelihoods\u001b[39;00m\n\u001b[1;32m    775\u001b[0m conditional_loglikelihoods \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conditional_loglikelihoods(params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/regime_switching/markov_switching.py:590\u001b[0m, in \u001b[0;36mMarkovSwitching.initial_probabilities\u001b[0;34m(self, params, regime_transition)\u001b[0m\n\u001b[1;32m    588\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(A)[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[0;32m--> 590\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSteady-state probabilities could not be\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    591\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m constructed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknown\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    593\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_probabilities\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Steady-state probabilities could not be constructed."
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "\n",
    "# Create copy of sentiment index\n",
    "df = sentiment_idx_df.copy()\n",
    "\n",
    "# set date as index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Split data into training and test\n",
    "train_data = df[:'2018-06-30'].copy()\n",
    "test_data = df['2018-07-01':].copy()\n",
    "\n",
    "# Initialize lists to store results\n",
    "transition_list = []\n",
    "prediction_list = []\n",
    "\n",
    "\n",
    "for i in test_data.index:\n",
    "    #print(len(train_data))\n",
    "    model = MarkovRegression(train_data['sentiment_score'], k_regimes=2, trend='c', switching_variance=True)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    #forecast = model_fit.predict(start=len(train_data), end=len(train_data))\n",
    "    # forecast = model_fit.forecast(steps=1)\n",
    "    # get_forecast = model_fit.get_forecast(steps=1)\n",
    "\n",
    "    # prediction = model_fit.predict(start=df.index[-1], end=df.index[-1] + pd.Timedelta(days=1))\n",
    "    prediction = result.predict(start=test_data.index[i], end=test_data.index[i])\n",
    "    prediction_list.append(prediction)\n",
    "\n",
    "    # transition = model_fit.regime_transition\n",
    "    # transition_list.append(transition)\n",
    "    # forecast_conf = get_forecast.conf_int(alpha=0.05)\n",
    "\n",
    "    #print(len(forecast))\n",
    "\n",
    "    #print(forecast)\n",
    "    # forecast_list.append(forecast)\n",
    "    # conf.append(forecast_conf)\n",
    "\n",
    "    #print(test_data[i])\n",
    "\n",
    "    # res = test_data[i] - forecast\n",
    "    # res_list.append(res)\n",
    "\n",
    "    # Expand estimation window\n",
    "    test_to_train = pd.Series([test_data[i]], index=[i])\n",
    "    #print(test_to_train)\n",
    "    train_data = pd.concat([train_data, test_to_train])\n",
    "    train_data = train_data.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/friederikeeichholz/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m MarkovRegression(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m], k_regimes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, trend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m, switching_variance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# Simplified Model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model_fit \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m---> 21\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model_fit\u001b[38;5;241m.\u001b[39mpredict(i, i)\n\u001b[1;32m     23\u001b[0m prediction_list\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[1;32m     25\u001b[0m transition_matrix \u001b[38;5;241m=\u001b[39m model_fit\u001b[38;5;241m.\u001b[39mregime_transition\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/wrapper.py:113\u001b[0m, in \u001b[0;36mmake_wrapper.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how[\u001b[38;5;241m0\u001b[39m], how[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how:\n\u001b[0;32m--> 113\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/regime_switching/markov_switching.py:1955\u001b[0m, in \u001b[0;36mMarkovSwitchingResults.predict\u001b[0;34m(self, start, end, probabilities, conditional)\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, probabilities\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1920\u001b[0m             conditional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;124;03m    In-sample prediction and out-of-sample forecasting\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[38;5;124;03m        forecasts. An (npredict x k_endog) array.\u001b[39;00m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend,\n\u001b[1;32m   1956\u001b[0m                               probabilities\u001b[38;5;241m=\u001b[39mprobabilities,\n\u001b[1;32m   1957\u001b[0m                               conditional\u001b[38;5;241m=\u001b[39mconditional)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/regime_switching/markov_switching.py:711\u001b[0m, in \u001b[0;36mMarkovSwitching.predict\u001b[0;34m(self, params, start, end, probabilities, conditional)\u001b[0m\n\u001b[1;32m    707\u001b[0m start, end, out_of_sample, prediction_index \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_prediction_index(start, end))\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_of_sample \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Perform in-sample prediction\u001b[39;00m\n\u001b[1;32m    714\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_conditional(params)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "\n",
    "# Create copy of sentiment index\n",
    "df = sentiment_idx_df.copy()\n",
    "\n",
    "# set date as index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Split data into training and test\n",
    "train_data = df[:'2018-06-30'].copy()\n",
    "test_data = df['2018-07-01':].copy()\n",
    "\n",
    "# Initialize lists to store results\n",
    "transition_list = []\n",
    "prediction_list = []\n",
    "\n",
    "for i in test_data.index:\n",
    "    model = MarkovRegression(train_data['sentiment_score'], k_regimes=2, trend='c', switching_variance=False)  # Simplified Model\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    prediction = model_fit.predict(i, i)\n",
    "\n",
    "    prediction_list.append(prediction)\n",
    "\n",
    "    transition_matrix = model_fit.regime_transition\n",
    "    transition_list.append(transition_matrix)\n",
    "\n",
    "    # Update train_data by appending the current test observation\n",
    "    train_data = train_data.append(test_data.loc[[i]])  # Simplify handling\n",
    "\n",
    "# Printing to check output\n",
    "print(prediction_list)\n",
    "print(transition_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rolling window (window size is 80% of data)\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Initialize lists to store MSE values and forecasts\n",
    "res_list = []\n",
    "forecast_list = []\n",
    "conf = []\n",
    "\n",
    "#initial training and test sets:\n",
    "#train_data = y_train.copy() # ['sentiment_score'].copy()\n",
    "#test_data = y_test.copy() #sentiment_df_test['sentiment_score'].copy()\n",
    "train_data = portfolio_df_sent[:'2018-07-01']['moving_average_10day'].dropna().copy()\n",
    "test_data = portfolio_df_sent['2018-07-01':]['moving_average_10day'].copy()\n",
    "\n",
    "for i in test_data.index:\n",
    "    #print(len(train_data))\n",
    "    # model = AutoReg(train_data, lags=optimal_lag_bic) # optimal lag = 10\n",
    "    model = ARIMA(train_data, order=(10, 0, 10))\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    #forecast = model_fit.predict(start=len(train_data), end=len(train_data))\n",
    "    # forecast = model_fit.forecast(steps=1)\n",
    "    get_forecast = model_fit.get_forecast(steps=1)\n",
    "\n",
    "    forecast = get_forecast.predicted_mean\n",
    "    forecast_conf = get_forecast.conf_int(alpha=0.05)\n",
    "\n",
    "    #print(len(forecast))\n",
    "\n",
    "    #print(forecast)\n",
    "    forecast_list.append(forecast)\n",
    "    conf.append(forecast_conf)\n",
    "\n",
    "    #print(test_data[i])\n",
    "\n",
    "    res = test_data[i] - forecast\n",
    "    res_list.append(res)\n",
    "\n",
    "    # Expand estimation window\n",
    "    test_to_train = pd.Series([test_data[i]], index=[i])\n",
    "    #print(test_to_train)\n",
    "    train_data = pd.concat([train_data, test_to_train])\n",
    "    train_data = train_data.iloc[1:]\n",
    "    #print(len(train_data))\n",
    "\n",
    "\n",
    "    #print(train_data[-5:])\n",
    "\n",
    "# Calculate the overall average MSE\n",
    "mse = np.mean(np.square(res))\n",
    "print(\"Overall average MSE:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
