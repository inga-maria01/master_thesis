{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and define sharpe function to evaluate the models: \n",
    "#need volatility data and the data from the risk_adjusted_returns file:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Get volatility historical data:\n",
    "url_volatility = 'https://raw.githubusercontent.com/inga-maria01/master_thesis/main/data/volatility_data.csv'\n",
    "volatility_df = pd.read_csv(url_volatility)\n",
    "#make the date a datetime object:\n",
    "volatility_df['Date'] = pd.to_datetime(volatility_df['Date'])\n",
    "\n",
    "# first we need the historical data: \n",
    "url_nasdaq_price = 'https://raw.githubusercontent.com/inga-maria01/master_thesis/main/data/QQQ.csv'\n",
    "price_df = pd.read_csv(url_nasdaq_price)\n",
    "price_df['Date'] = pd.to_datetime(price_df['Date'])\n",
    "price_df.head()\n",
    "#this dataset includes the prices and the volume!\n",
    "# we now need to calculate the returns:\n",
    "price_df['r_ndq'] = (price_df['Adj Close'] - price_df['Adj Close'].shift(1)) / price_df['Adj Close'].shift(1)\n",
    "price_df.dropna(inplace=True)\n",
    "price_df.head()\n",
    "\n",
    "rf_df = pd.read_csv('https://raw.githubusercontent.com/inga-maria01/master_thesis/main/data/IEF.csv')\n",
    "rf_df['r_rf'] = (rf_df['Adj Close'] - rf_df['Adj Close'].shift(1)) / rf_df['Adj Close'].shift(1)\n",
    "rf_df.dropna(inplace=True)\n",
    "rf_df['Date'] = pd.to_datetime(rf_df['Date'])\n",
    "\n",
    "portfolio_df = pd.merge(price_df[['Date', 'r_ndq']], \n",
    "                     rf_df[['Date', 'r_rf']], \n",
    "                     on='Date', \n",
    "                     how='inner')\n",
    "\n",
    "portfolio_df = pd.merge(portfolio_df,  \n",
    "                     volatility_df[['Date', 'Price']],\n",
    "                     on='Date', \n",
    "                     how='inner')\n",
    "\n",
    "portfolio_df.rename(columns={'Price' : 'Volatility'}, inplace = True)\n",
    "portfolio_df.head()\n",
    "\n",
    "r_rf_df = pd.read_csv('https://raw.githubusercontent.com/inga-maria01/master_thesis/main/data/risk_free_rate.csv')\n",
    "\n",
    "#divide by 100 because it was already in % -> we dont want that here!\n",
    "#then divide by 252 since its on a yearly basis but everything else is on a daily basis\n",
    "#(252 ~ number of us trading days a year)\n",
    "r_rf_df['daily_rf'] = r_rf_df['rf_rate']/(100*250)\n",
    "r_rf_df['Date'] = pd.to_datetime(r_rf_df['Date'])\n",
    "#r_rf_df.set_index('Date', inplace=True)\n",
    "r_rf_df.head()\n",
    "\n",
    "portfolio_df = pd.merge(portfolio_df, \n",
    "                        r_rf_df[['Date', 'rf_rate', 'daily_rf']], \n",
    "                        on='Date', \n",
    "                        how='inner')\n",
    "\n",
    "sentiment_index_df = pd.read_excel('https://raw.githubusercontent.com/inga-maria01/master_thesis/main/index/sentiment_index_unweighted_v7.xlsx')\n",
    "sentiment_index_df.rename(columns={'date':'Date'}, inplace=True)\n",
    "# sentiment_index_df['lag_sentiment'] = sentiment_index_df['sentiment_score'].shift(1)\n",
    "sentiment_index_df.head()\n",
    "\n",
    "portfolio_df_sent = pd.merge(portfolio_df, sentiment_index_df, on='Date', how='inner')\n",
    "portfolio_df_sent.set_index('Date', inplace=True)\n",
    "portfolio_df_sent['moving_average_10day'] = portfolio_df_sent['sentiment_score'].rolling(window = 10).mean() # maybe try exponential?\n",
    "portfolio_df_sent['moving_average_5day'] = portfolio_df_sent['sentiment_score'].rolling(window = 5).mean() # maybe try exponential?\n",
    "portfolio_df_sent['moving_average_20day'] = portfolio_df_sent['sentiment_score'].rolling(window = 20).mean() # maybe try exponential?\n",
    "portfolio_df_sent['moving_average_30day'] = portfolio_df_sent['sentiment_score'].rolling(window = 30).mean() # maybe try exponential?\n",
    "portfolio_df_sent['moving_average_15day'] = portfolio_df_sent['sentiment_score'].rolling(window = 15).mean() # maybe try exponential?\n",
    "\n",
    "#want to just look at the training period for threshold optimization\n",
    "#and then just at the test period for calculating the sharpe\n",
    "portfolio_df_sent_train = portfolio_df_sent[:'2018-06-30'].copy()\n",
    "portfolio_df_sent_test = portfolio_df_sent['2018-07-01':].copy()\n",
    "\n",
    "\n",
    "data_df = pd.merge(portfolio_df_sent, price_df[['Date', 'Close', 'Adj Close']], on='Date', how='inner')\n",
    "data_df = data_df.rename(columns={'Close': 'close_qqq', 'Adj Close': 'adj_close_qqq'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future MA includes today as today's sentiment is still unknown before the trading day \n",
    "portfolio_df_sent['sentiment_ma_next_10'] = portfolio_df_sent['sentiment_score'].rolling(window=10).mean().shift(-9)\n",
    "\n",
    "portfolio_df_sent['sentiment_ma_next_5'] = portfolio_df_sent['sentiment_score'].rolling(window=5).mean().shift(-4)\n",
    "\n",
    "portfolio_df_sent['sentiment_ma_next_15'] = portfolio_df_sent['sentiment_score'].rolling(window=15).mean().shift(-14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_past = portfolio_df_sent.copy()\n",
    "# ma_past = ma_past.drop(columns='sentiment_ma_next_10')\n",
    "# ma_past = ma_past.dropna()\n",
    "\n",
    "ma_future = portfolio_df_sent.copy()\n",
    "ma_future = ma_future[ma_future['sentiment_ma_next_10'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_past = portfolio_df_sent.copy()\n",
    "# ma_past = ma_past.drop(columns='sentiment_ma_next_10')\n",
    "# ma_past = ma_past.dropna()\n",
    "\n",
    "ma_future_15day = portfolio_df_sent.copy()\n",
    "ma_future_15day = ma_future_15day[ma_future_15day['sentiment_ma_next_15'].notna()]\n",
    "ma_future_15day = ma_future_15day[ma_future_15day['moving_average_15day'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_past = portfolio_df_sent.copy()\n",
    "# ma_past = ma_past.drop(columns='sentiment_ma_next_10')\n",
    "# ma_past = ma_past.dropna()\n",
    "\n",
    "ma_future_5day = portfolio_df_sent.copy()\n",
    "ma_future_5day = ma_future_5day[ma_future_5day['sentiment_ma_next_5'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_correct_10day(sentiment, version): # version is either sentiment_score or moving_average_10day\n",
    "    w_ndq = []\n",
    "    w_rf = []\n",
    "\n",
    "    # Assuming 'sentiment' is a pandas Series\n",
    "    \n",
    "    upper = ma_future[version].shift(1).rolling(95).quantile(0.75) #apply(lambda x: weighted_quantile(x, quantile=0.75), raw=True)\n",
    "    lower = ma_future[version].shift(1).rolling(95).quantile(0.25) #apply(lambda x: weighted_quantile(x, quantile=0.25), raw=True)\n",
    "    test_sent = sentiment['2018-07-01':]\n",
    "    test_df = ma_future['2018-07-01':].copy()\n",
    "    for i in test_sent.index:\n",
    "        score = sentiment[i]\n",
    "        if score > upper[i]: #23: changing to see if it improves\n",
    "            w_ndq.append(0.8)\n",
    "            w_rf.append(0.2)\n",
    "        elif score <= upper[i] and score > lower[i]: # was 20:\n",
    "            w_ndq.append(0.6)\n",
    "            w_rf.append(0.4)\n",
    "        elif score <= lower[i]:\n",
    "            w_ndq.append(0.2)\n",
    "            w_rf.append(0.8)\n",
    "    test_df['w_ndq'] = w_ndq\n",
    "    test_df['w_rf'] = w_rf\n",
    "    test_df['r_portfolio'] = test_df['w_ndq'] * test_df['r_ndq'] + test_df['w_rf'] * test_df['r_rf']\n",
    "    test_df['excess returns'] = test_df['r_portfolio'] - test_df['daily_rf']\n",
    "    test_df['trading day'] = (test_df['w_ndq'] != test_df['w_ndq'].shift(1)).astype(int)\n",
    "    \n",
    "    test_df.reset_index(inplace=True)\n",
    "    # Identify maximum index in the dataset\n",
    "    max_index = test_df.index.max()\n",
    "\n",
    "    # Initialize starting portfolio value\n",
    "    initial_portfolio_value = 1\n",
    "\n",
    "    # Create a new DataFrame to store calculated values\n",
    "    df_calc = pd.DataFrame(index=test_df.index, columns=['portfolio_value', 'ndq_start', 'rf_start', 'ndq_end', 'rf_end'])\n",
    "    \n",
    "    # Initialize first values from row 0\n",
    "    df_calc.loc[0, 'portfolio_value'] = initial_portfolio_value\n",
    "    df_calc.loc[0, 'ndq_start'] = 0\n",
    "    df_calc.loc[0, 'rf_start'] = 0\n",
    "    df_calc.loc[0, 'ndq_end'] = w_ndq[0] * initial_portfolio_value\n",
    "    df_calc.loc[0, 'rf_end'] = w_rf[0] * initial_portfolio_value\n",
    "\n",
    "    # Loop through rows from 1 to max_index to calculate the required columns\n",
    "    for i in range(1, max_index + 1):\n",
    "        # Calculate ndq_start and rf_start\n",
    "        df_calc.loc[i, 'ndq_start'] = df_calc.loc[i - 1, 'ndq_end'] * (1 + test_df.loc[i, 'r_ndq'])\n",
    "        df_calc.loc[i, 'rf_start'] = df_calc.loc[i - 1, 'rf_end'] * (1 + test_df.loc[i, 'r_rf'])\n",
    "\n",
    "        # Calculate the new portfolio value\n",
    "        df_calc.loc[i, 'portfolio_value'] = df_calc.loc[i, 'ndq_start'] + df_calc.loc[i, 'rf_start']\n",
    "\n",
    "        # Calculate ndq_end and rf_end based on updated portfolio value\n",
    "        df_calc.loc[i, 'ndq_end'] =  w_ndq[i] * df_calc.loc[i, 'portfolio_value']\n",
    "        df_calc.loc[i, 'rf_end'] = w_rf[i] * df_calc.loc[i, 'portfolio_value']\n",
    "    \n",
    "    return2019 = (df_calc['portfolio_value'][-1:]/df_calc['portfolio_value'][0]) **(1/(365/250)) - 1\n",
    "    risk_free2019 = test_df['rf_rate'].mean()/100\n",
    "    std2019 = np.std(test_df['excess returns'])*np.sqrt(250)\n",
    "\n",
    "    test_df.set_index('Date', inplace=True)\n",
    "    \n",
    "    return (return2019 - risk_free2019)/std2019, df_calc, test_df, upper, lower\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_correct_5day(sentiment, version): # version is either sentiment_score or moving_average_10day\n",
    "    w_ndq = []\n",
    "    w_rf = []\n",
    "\n",
    "    # Assuming 'sentiment' is a pandas Series\n",
    "    \n",
    "    upper = ma_future_5day[version].shift(1).rolling(63).quantile(0.75) #apply(lambda x: weighted_quantile(x, quantile=0.75), raw=True)\n",
    "    lower = ma_future_5day[version].shift(1).rolling(63).quantile(0.25) #apply(lambda x: weighted_quantile(x, quantile=0.25), raw=True)\n",
    "    test_sent = sentiment['2018-07-01':]\n",
    "    test_df = ma_future_5day['2018-07-01':].copy()\n",
    "    for i in test_sent.index:\n",
    "        score = sentiment[i]\n",
    "        if score > upper[i]: #23: changing to see if it improves\n",
    "            w_ndq.append(0.8)\n",
    "            w_rf.append(0.2)\n",
    "        elif score <= upper[i] and score > lower[i]: # was 20:\n",
    "            w_ndq.append(0.6)\n",
    "            w_rf.append(0.4)\n",
    "        elif score <= lower[i]:\n",
    "            w_ndq.append(0.2)\n",
    "            w_rf.append(0.8)\n",
    "    test_df['w_ndq'] = w_ndq\n",
    "    test_df['w_rf'] = w_rf\n",
    "    test_df['r_portfolio'] = test_df['w_ndq'] * test_df['r_ndq'] + test_df['w_rf'] * test_df['r_rf']\n",
    "    test_df['excess returns'] = test_df['r_portfolio'] - test_df['daily_rf']\n",
    "    test_df['trading day'] = (test_df['w_ndq'] != test_df['w_ndq'].shift(1)).astype(int)\n",
    "    \n",
    "    test_df.reset_index(inplace=True)\n",
    "    # Identify maximum index in the dataset\n",
    "    max_index = test_df.index.max()\n",
    "\n",
    "    # Initialize starting portfolio value\n",
    "    initial_portfolio_value = 1\n",
    "\n",
    "    # Create a new DataFrame to store calculated values\n",
    "    df_calc = pd.DataFrame(index=test_df.index, columns=['portfolio_value', 'ndq_start', 'rf_start', 'ndq_end', 'rf_end'])\n",
    "    \n",
    "    # Initialize first values from row 0\n",
    "    df_calc.loc[0, 'portfolio_value'] = initial_portfolio_value\n",
    "    df_calc.loc[0, 'ndq_start'] = 0\n",
    "    df_calc.loc[0, 'rf_start'] = 0\n",
    "    df_calc.loc[0, 'ndq_end'] = w_ndq[0] * initial_portfolio_value\n",
    "    df_calc.loc[0, 'rf_end'] = w_rf[0] * initial_portfolio_value\n",
    "\n",
    "    # Loop through rows from 1 to max_index to calculate the required columns\n",
    "    for i in range(1, max_index + 1):\n",
    "        # Calculate ndq_start and rf_start\n",
    "        df_calc.loc[i, 'ndq_start'] = df_calc.loc[i - 1, 'ndq_end'] * (1 + test_df.loc[i, 'r_ndq'])\n",
    "        df_calc.loc[i, 'rf_start'] = df_calc.loc[i - 1, 'rf_end'] * (1 + test_df.loc[i, 'r_rf'])\n",
    "\n",
    "        # Calculate the new portfolio value\n",
    "        df_calc.loc[i, 'portfolio_value'] = df_calc.loc[i, 'ndq_start'] + df_calc.loc[i, 'rf_start']\n",
    "\n",
    "        # Calculate ndq_end and rf_end based on updated portfolio value\n",
    "        df_calc.loc[i, 'ndq_end'] =  w_ndq[i] * df_calc.loc[i, 'portfolio_value']\n",
    "        df_calc.loc[i, 'rf_end'] = w_rf[i] * df_calc.loc[i, 'portfolio_value']\n",
    "    \n",
    "    return2019 = (df_calc['portfolio_value'][-1:]/df_calc['portfolio_value'][0]) **(1/(365/250)) - 1\n",
    "    risk_free2019 = test_df['rf_rate'].mean()/100\n",
    "    std2019 = np.std(test_df['excess returns'])*np.sqrt(250)\n",
    "\n",
    "    test_df.set_index('Date', inplace=True)\n",
    "    \n",
    "    return (return2019 - risk_free2019)/std2019, df_calc, test_df, upper, lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_correct_15day(sentiment, version): # version is either sentiment_score or moving_average_10day\n",
    "    w_ndq = []\n",
    "    w_rf = []\n",
    "\n",
    "    # Assuming 'sentiment' is a pandas Series\n",
    "    \n",
    "    upper = ma_future_15day[version].shift(1).rolling(63).quantile(0.75) #apply(lambda x: weighted_quantile(x, quantile=0.75), raw=True)\n",
    "    lower = ma_future_15day[version].shift(1).rolling(63).quantile(0.25) #apply(lambda x: weighted_quantile(x, quantile=0.25), raw=True)\n",
    "    test_sent = sentiment['2018-07-01':]\n",
    "    test_df = ma_future_15day['2018-07-01':].copy()\n",
    "    for i in test_sent.index:\n",
    "        score = sentiment[i]\n",
    "        if score > upper[i]: #23: changing to see if it improves\n",
    "            w_ndq.append(0.8)\n",
    "            w_rf.append(0.2)\n",
    "        elif score <= upper[i] and score > lower[i]: # was 20:\n",
    "            w_ndq.append(0.6)\n",
    "            w_rf.append(0.4)\n",
    "        elif score <= lower[i]:\n",
    "            w_ndq.append(0.2)\n",
    "            w_rf.append(0.8)\n",
    "    test_df['w_ndq'] = w_ndq\n",
    "    test_df['w_rf'] = w_rf\n",
    "    test_df['r_portfolio'] = test_df['w_ndq'] * test_df['r_ndq'] + test_df['w_rf'] * test_df['r_rf']\n",
    "    test_df['excess returns'] = test_df['r_portfolio'] - test_df['daily_rf']\n",
    "    test_df['trading day'] = (test_df['w_ndq'] != test_df['w_ndq'].shift(1)).astype(int)\n",
    "    \n",
    "    test_df.reset_index(inplace=True)\n",
    "    # Identify maximum index in the dataset\n",
    "    max_index = test_df.index.max()\n",
    "\n",
    "    # Initialize starting portfolio value\n",
    "    initial_portfolio_value = 1\n",
    "\n",
    "    # Create a new DataFrame to store calculated values\n",
    "    df_calc = pd.DataFrame(index=test_df.index, columns=['portfolio_value', 'ndq_start', 'rf_start', 'ndq_end', 'rf_end'])\n",
    "    \n",
    "    # Initialize first values from row 0\n",
    "    df_calc.loc[0, 'portfolio_value'] = initial_portfolio_value\n",
    "    df_calc.loc[0, 'ndq_start'] = 0\n",
    "    df_calc.loc[0, 'rf_start'] = 0\n",
    "    df_calc.loc[0, 'ndq_end'] = w_ndq[0] * initial_portfolio_value\n",
    "    df_calc.loc[0, 'rf_end'] = w_rf[0] * initial_portfolio_value\n",
    "\n",
    "    # Loop through rows from 1 to max_index to calculate the required columns\n",
    "    for i in range(1, max_index + 1):\n",
    "        # Calculate ndq_start and rf_start\n",
    "        df_calc.loc[i, 'ndq_start'] = df_calc.loc[i - 1, 'ndq_end'] * (1 + test_df.loc[i, 'r_ndq'])\n",
    "        df_calc.loc[i, 'rf_start'] = df_calc.loc[i - 1, 'rf_end'] * (1 + test_df.loc[i, 'r_rf'])\n",
    "\n",
    "        # Calculate the new portfolio value\n",
    "        df_calc.loc[i, 'portfolio_value'] = df_calc.loc[i, 'ndq_start'] + df_calc.loc[i, 'rf_start']\n",
    "\n",
    "        # Calculate ndq_end and rf_end based on updated portfolio value\n",
    "        df_calc.loc[i, 'ndq_end'] =  w_ndq[i] * df_calc.loc[i, 'portfolio_value']\n",
    "        df_calc.loc[i, 'rf_end'] = w_rf[i] * df_calc.loc[i, 'portfolio_value']\n",
    "    \n",
    "    return2019 = (df_calc['portfolio_value'][-1:]/df_calc['portfolio_value'][0]) **(1/(365/250)) - 1\n",
    "    risk_free2019 = test_df['rf_rate'].mean()/100\n",
    "    std2019 = np.std(test_df['excess returns'])*np.sqrt(250)\n",
    "\n",
    "    test_df.set_index('Date', inplace=True)\n",
    "    \n",
    "    return (return2019 - risk_free2019)/std2019, df_calc, test_df, upper, lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363    3.442417\n",
      "Name: portfolio_value, dtype: object\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "sharpe_act_future_ma, df_calc_act_future_ma, test_df_act_future_ma, upper_act_future_ma, lower_act_future_ma = sharpe_correct_10day(ma_future['sentiment_ma_next_10'], 'moving_average_20day')\n",
    "print(sharpe_act_future_ma)\n",
    "print(test_df_act_future_ma['trading day'].sum())\n",
    "#63 days results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363    2.7689\n",
      "Name: portfolio_value, dtype: object\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "sharpe_act_future_ma, df_calc_act_future_ma, test_df_act_future_ma, upper_act_future_ma, lower_act_future_ma = sharpe_correct_10day(ma_future['sentiment_ma_next_10'], 'moving_average_20day')\n",
    "print(sharpe_act_future_ma)\n",
    "print(test_df_act_future_ma['trading day'].sum())\n",
    "#126 days results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363    2.965093\n",
      "Name: portfolio_value, dtype: object\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "sharpe_act_future_ma, df_calc_act_future_ma, test_df_act_future_ma, upper_act_future_ma, lower_act_future_ma = sharpe_correct_10day(ma_future['sentiment_ma_next_10'], 'moving_average_20day')\n",
    "print(sharpe_act_future_ma)\n",
    "print(test_df_act_future_ma['trading day'].sum())\n",
    "#95 days results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358    3.075126\n",
      "Name: portfolio_value, dtype: object\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "sharpe_act_future_ma, df_calc_act_future_ma, test_df_act_future_ma, upper_act_future_ma, lower_act_future_ma = sharpe_correct_15day(ma_future_15day['sentiment_ma_next_15'], 'moving_average_30day')\n",
    "print(sharpe_act_future_ma)\n",
    "print(test_df_act_future_ma['trading day'].sum())\n",
    "#95 days results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
